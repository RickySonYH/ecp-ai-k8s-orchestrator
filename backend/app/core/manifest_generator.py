# [advice from AI] ECP-AI Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±ê¸°
"""
Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìë™ ìƒì„±
- í…Œë„Œì‹œ ì‚¬ì–‘ ê¸°ë°˜ YAML ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
- Jinja2 í…œí”Œë¦¿ ê¸°ë°˜ ë™ì  ìƒì„±
- ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ZIP íŒŒì¼ ìƒì„±
"""

import os
import yaml
import zipfile
from io import BytesIO
from typing import Dict, Any, List
from pathlib import Path
from jinja2 import Template, Environment, FileSystemLoader
import structlog

from .tenant_manager import TenantSpecs

logger = structlog.get_logger(__name__)


class ManifestGenerator:
    """Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self, templates_path: str = "/app/config/k8s-templates"):
        self.templates_path = Path(templates_path)
        self.jinja_env = Environment(
            loader=FileSystemLoader(str(self.templates_path)),
            autoescape=False,
            trim_blocks=True,
            lstrip_blocks=True
        )
        
        # ê¸°ë³¸ í…œí”Œë¦¿ë“¤ (ë‚´ì¥)
        self.builtin_templates = {
            "namespace": self._get_namespace_template(),
            "deployment": self._get_deployment_template(),
            "service": self._get_service_template(),
            "hpa": self._get_hpa_template(),
            "configmap": self._get_configmap_template(),
            "networkpolicy": self._get_networkpolicy_template()
        }
        
        logger.info("ManifestGenerator ì´ˆê¸°í™” ì™„ë£Œ", templates_path=str(self.templates_path))
    
    def generate_tenant_manifests(self, tenant_specs: TenantSpecs) -> Dict[str, str]:
        """
        í…Œë„Œì‹œ ì „ì²´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
        """
        logger.info("í…Œë„Œì‹œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì‹œì‘", tenant_id=tenant_specs.tenant_id)
        
        manifests = {}
        
        # 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        manifests["01-namespace.yaml"] = self._generate_namespace(tenant_specs)
        
        # 2. ConfigMap
        manifests["02-configmap.yaml"] = self._generate_configmap(tenant_specs)
        
        # 3. ì„œë¹„ìŠ¤ë³„ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ (ê¸°ë³¸ ì„œë¹„ìŠ¤ë“¤)
        service_count = 3
        
        # ê¸°ë³¸ ì„œë¹„ìŠ¤ë“¤ ìƒì„±
        basic_services = ["callbot", "chatbot", "advisor", "stt", "tts", "ta", "qa"]
        for service_name in basic_services:
            # Deployment
            manifests[f"{service_count:02d}-{service_name}-deployment.yaml"] = \
                self._generate_deployment(tenant_specs, service_name)
            
            # Service
            manifests[f"{service_count:02d}-{service_name}-service.yaml"] = \
                self._generate_service(tenant_specs, service_name)
            
            # HPA (ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”)
            manifests[f"{service_count:02d}-{service_name}-hpa.yaml"] = \
                self._generate_hpa(tenant_specs, service_name)
            
            service_count += 1
        
        # 4. ë„¤íŠ¸ì›Œí¬ ì •ì±…
        manifests["90-networkpolicy.yaml"] = self._generate_networkpolicy(tenant_specs)
        
        # 5. ëª¨ë‹ˆí„°ë§ ì„¤ì •
        manifests["91-monitoring.yaml"] = self._generate_monitoring(tenant_specs)
        
        logger.info(
            "í…Œë„Œì‹œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ",
            tenant_id=tenant_specs.tenant_id,
            manifest_count=len(manifests)
        )
        
        return manifests
    
    def create_deployment_package(self, tenant_specs: TenantSpecs) -> BytesIO:
        """
        ë°°í¬ íŒ¨í‚¤ì§€ ZIP íŒŒì¼ ìƒì„±
        """
        logger.info("ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„± ì‹œì‘", tenant_id=tenant_specs.tenant_id)
        
        # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
        manifests = self.generate_tenant_manifests(tenant_specs)
        
        # ZIP íŒŒì¼ ìƒì„±
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            
            # Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì¶”ê°€
            for filename, content in manifests.items():
                zip_file.writestr(f"k8s-manifests/{filename}", content)
            
            # ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
            deploy_script = self._generate_deploy_script(tenant_specs)
            zip_file.writestr("deploy.sh", deploy_script)
            
            # ì‚­ì œ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
            cleanup_script = self._generate_cleanup_script(tenant_specs)
            zip_file.writestr("cleanup.sh", cleanup_script)
            
            # README ì¶”ê°€
            readme_content = self._generate_readme(tenant_specs)
            zip_file.writestr("README.md", readme_content)
            
            # í…Œë„Œì‹œ ì‚¬ì–‘ JSON ì¶”ê°€
            import json
            try:
                specs_json = json.dumps(tenant_specs.model_dump(), indent=2, ensure_ascii=False)
                zip_file.writestr("tenant-specs.json", specs_json)
            except Exception as e:
                logger.warning("í…Œë„Œì‹œ ì‚¬ì–‘ JSON ìƒì„± ì‹¤íŒ¨", error=str(e))
                # ê¸°ë³¸ ì •ë³´ë§Œ í¬í•¨
                basic_specs = {
                    "tenant_id": tenant_specs.tenant_id,
                    "preset": tenant_specs.preset,
                    "services": ["callbot", "chatbot", "advisor", "stt", "tts", "ta", "qa"]
                }
                specs_json = json.dumps(basic_specs, indent=2, ensure_ascii=False)
                zip_file.writestr("tenant-specs.json", specs_json)
        
        zip_buffer.seek(0)
        
        logger.info("ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„± ì™„ë£Œ", tenant_id=tenant_specs.tenant_id)
        return zip_buffer
    
    def _generate_namespace(self, tenant_specs: TenantSpecs) -> str:
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        template = Template(self.builtin_templates["namespace"])
        return template.render(
            tenant_id=tenant_specs.tenant_id,
            tenant_preset=tenant_specs.preset
        )
    
    def _generate_deployment(self, tenant_specs: TenantSpecs, service_name: str) -> str:
        """Deployment ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        try:
            template = Template(self.builtin_templates["deployment"])
            
            # GPU í• ë‹¹ ì •ë³´ (ìƒˆë¡œìš´ TenantSpecs ëª¨ë¸ ê¸°ë°˜)
            has_gpu = service_name in ["tts", "nlp", "aicm"] and tenant_specs.gpu_count > 0
            gpu_type = tenant_specs.gpu_type.value if has_gpu else "t4"
            gpu_count = 1 if has_gpu else 0
            
            # ê¸°ë³¸ container_specs ì„¤ì •
            container_specs = {
                "image": f"ecp-ai/{service_name}:latest",
                "ports": [{"containerPort": 8080, "protocol": "TCP"}],
                "env": [],
                "resources": {
                    "requests": {"cpu": "100m", "memory": "256Mi"},
                    "limits": {"cpu": "1000m", "memory": "1Gi"}
                }
            }
            
            return template.render(
                tenant_id=tenant_specs.tenant_id,
                service_name=service_name,
                replicas=1,
                has_gpu=has_gpu,
                gpu_type=gpu_type,
                gpu_count=gpu_count,
                namespace=f"{tenant_specs.tenant_id}-ecp-ai",
                container_specs=container_specs
            )
        except Exception as e:
            logger.error("Deployment ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨", 
                        service_name=service_name, error=str(e))
            # ê¸°ë³¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë°˜í™˜
            return self._generate_basic_deployment(tenant_specs, service_name)
    
    def _generate_basic_deployment(self, tenant_specs: TenantSpecs, service_name: str) -> str:
        """ê¸°ë³¸ Deployment ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± (í…œí”Œë¦¿ ì˜¤ë¥˜ ì‹œ í´ë°±)"""
        # GPU í• ë‹¹ ì •ë³´ (ìƒˆë¡œìš´ TenantSpecs ëª¨ë¸ ê¸°ë°˜)
        has_gpu = service_name in ["tts", "nlp", "aicm"] and tenant_specs.gpu_count > 0
        
        basic_deployment = f"""---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {service_name}
  namespace: {tenant_specs.tenant_id}-ecp-ai
  labels:
    app: {service_name}
    tenant: {tenant_specs.tenant_id}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {service_name}
      tenant: {tenant_specs.tenant_id}
  template:
    metadata:
      labels:
        app: {service_name}
        tenant: {tenant_specs.tenant_id}
        monitoring: enabled
    spec:"""

        if has_gpu:
            gpu_type = tenant_specs.gpu_type.value
            basic_deployment += f"""
      nodeSelector:
        accelerator: nvidia-{gpu_type}
      tolerations:
      - key: nvidia.com/gpu
        operator: Equal
        value: present
        effect: NoSchedule"""

        basic_deployment += f"""
      containers:
      - name: {service_name}
        image: ecp-ai/{service_name}:latest
        ports:
        - containerPort: 8080
        env:
        - name: TENANT_ID
          value: {tenant_specs.tenant_id}
        - name: SERVICE_NAME
          value: {service_name}"""

        if has_gpu:
            basic_deployment += f"""
        resources:
          requests:
            nvidia.com/gpu: 1
            cpu: 1000m
            memory: 2Gi
          limits:
            nvidia.com/gpu: 1
            cpu: 4000m
            memory: 8Gi"""
        else:
            basic_deployment += f"""
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi"""

        basic_deployment += f"""
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
"""
        
        return basic_deployment
    
    def _generate_service(self, tenant_specs: TenantSpecs, service_name: str) -> str:
        """Service ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        try:
            template = Template(self.builtin_templates["service"])
            
            # ê¸°ë³¸ í¬íŠ¸ ì„¤ì •
            ports = [{"containerPort": 8080}]
            
            return template.render(
                tenant_id=tenant_specs.tenant_id,
                service_name=service_name,
                ports=ports,
                namespace=f"{tenant_specs.tenant_id}-ecp-ai"
            )
        except Exception as e:
            logger.error("Service ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨", 
                        service_name=service_name, error=str(e))
            # ê¸°ë³¸ Service ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë°˜í™˜
            return f"""---
apiVersion: v1
kind: Service
metadata:
  name: {service_name}-service
  namespace: {tenant_specs.tenant_id}-ecp-ai
  labels:
    app: {service_name}
    tenant: {tenant_specs.tenant_id}
    monitoring: enabled
spec:
  selector:
    app: {service_name}
    tenant: {tenant_specs.tenant_id}
  ports:
  - name: http
    port: 8080
    targetPort: 8080
    protocol: TCP
  type: ClusterIP
"""
    
    def _generate_hpa(self, tenant_specs: TenantSpecs, service_name: str) -> str:
        """HPA ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        template = Template(self.builtin_templates["hpa"])
        
        # ê¸°ë³¸ ìŠ¤ì¼€ì¼ë§ ì„¤ì •
        min_replicas = 1
        max_replicas = 10
        target_cpu = 70
        
        return template.render(
            tenant_id=tenant_specs.tenant_id,
            service_name=service_name,
            min_replicas=min_replicas,
            max_replicas=max_replicas,
            target_cpu=target_cpu,
            namespace=f"{tenant_specs.tenant_id}-ecp-ai"
        )
    
    def _generate_configmap(self, tenant_specs: TenantSpecs) -> str:
        """ConfigMap ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        try:
            template = Template(self.builtin_templates["configmap"])
            
            return template.render(
                tenant_id=tenant_specs.tenant_id,
                tenant_specs=tenant_specs,
                namespace=f"{tenant_specs.tenant_id}-ecp-ai"
            )
        except Exception as e:
            logger.error("ConfigMap ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨", error=str(e))
            # ê¸°ë³¸ ConfigMap ë°˜í™˜
            return f"""---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ecp-config
  namespace: {tenant_specs.tenant_id}-ecp-ai
  labels:
    tenant: {tenant_specs.tenant_id}
data:
  tenant-config.yaml: |
    tenantId: {tenant_specs.tenant_id}
    preset: {tenant_specs.preset}
    services: {{}}
    resources:
      gpu_type: {tenant_specs.gpu_type.value}
      auto_scaling: true
"""
    
    def _generate_networkpolicy(self, tenant_specs: TenantSpecs) -> str:
        """NetworkPolicy ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        template = Template(self.builtin_templates["networkpolicy"])
        
        return template.render(
            tenant_id=tenant_specs.tenant_id,
            namespace=f"{tenant_specs.tenant_id}-ecp-ai"
        )
    
    def _generate_monitoring(self, tenant_specs: TenantSpecs) -> str:
        """ëª¨ë‹ˆí„°ë§ ì„¤ì • ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±"""
        monitoring_yaml = {
            "apiVersion": "monitoring.coreos.com/v1",
            "kind": "ServiceMonitor",
            "metadata": {
                "name": "ecp-ai-monitoring",
                "namespace": f"{tenant_specs.tenant_id}-ecp-ai",
                "labels": {
                    "tenant": tenant_specs.tenant_id,
                    "app.kubernetes.io/name": "ecp-ai"
                }
            },
            "spec": {
                "selector": {
                    "matchLabels": {
                        "monitoring": "enabled"
                    }
                },
                "endpoints": [
                    {
                        "port": "metrics",
                        "interval": "30s",
                        "path": "/metrics"
                    }
                ]
            }
        }
        
        return yaml.dump(monitoring_yaml, default_flow_style=False, allow_unicode=True)
    
    def _generate_deploy_script(self, tenant_specs: TenantSpecs) -> str:
        """ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        return f"""#!/bin/bash
# [advice from AI] ECP-AI í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ğŸš€ ECP-AI í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ë°°í¬ ì‹œì‘"
echo "í”„ë¦¬ì…‹: {tenant_specs.preset}"
echo "GPU íƒ€ì…: {tenant_specs.gpu_type.value}"
echo "ì˜ˆìƒ ë¦¬ì†ŒìŠ¤: GPU {tenant_specs.gpu_count}ê°œ, CPU {tenant_specs.cpu_cores}ì½”ì–´"
echo ""

# 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
echo "ğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì¤‘..."
kubectl apply -f k8s-manifests/01-namespace.yaml

# 2. ConfigMap ìƒì„±
echo "âš™ï¸ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
kubectl apply -f k8s-manifests/02-configmap.yaml

# 3. ì„œë¹„ìŠ¤ë³„ ë°°í¬
echo "ğŸ› ï¸ ì„œë¹„ìŠ¤ ë°°í¬ ì¤‘..."
for manifest in k8s-manifests/*-deployment.yaml; do
    if [ -f "$manifest" ]; then
        echo "ë°°í¬ ì¤‘: $(basename $manifest)"
        kubectl apply -f "$manifest"
    fi
done

for manifest in k8s-manifests/*-service.yaml; do
    if [ -f "$manifest" ]; then
        echo "ì„œë¹„ìŠ¤ ìƒì„±: $(basename $manifest)"
        kubectl apply -f "$manifest"
    fi
done

# 4. ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì„¤ì •
echo "ğŸ“ˆ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì„¤ì • ì¤‘..."
for manifest in k8s-manifests/*-hpa.yaml; do
    if [ -f "$manifest" ]; then
        echo "HPA ìƒì„±: $(basename $manifest)"
        kubectl apply -f "$manifest"
    fi
done

# 5. ë„¤íŠ¸ì›Œí¬ ì •ì±… ë° ëª¨ë‹ˆí„°ë§
echo "ğŸ”’ ë³´ì•ˆ ì •ì±… ì„¤ì • ì¤‘..."
kubectl apply -f k8s-manifests/90-networkpolicy.yaml
kubectl apply -f k8s-manifests/91-monitoring.yaml

echo ""
echo "âœ… í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ë°°í¬ ì™„ë£Œ!"
echo ""
echo "ğŸ“Š ìƒíƒœ í™•ì¸:"
echo "  kubectl get pods -n {tenant_specs.tenant_id}-ecp-ai"
echo "  kubectl get services -n {tenant_specs.tenant_id}-ecp-ai"
echo "  kubectl get hpa -n {tenant_specs.tenant_id}-ecp-ai"
echo ""
echo "ğŸ” ë¡œê·¸ í™•ì¸:"
echo "  kubectl logs -f deployment/<service-name> -n {tenant_specs.tenant_id}-ecp-ai"
echo ""
echo "ğŸ—‘ï¸ ì‚­ì œ ë°©ë²•:"
echo "  ./cleanup.sh"
"""

    def _generate_cleanup_script(self, tenant_specs: TenantSpecs) -> str:
        """ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        return f"""#!/bin/bash
# [advice from AI] ECP-AI í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ğŸ—‘ï¸ ECP-AI í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ì‚­ì œ ì‹œì‘"
echo ""

read -p "ì •ë§ë¡œ í…Œë„Œì‹œ '{tenant_specs.tenant_id}'ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "ì‚­ì œ ì·¨ì†Œë¨"
    exit 0
fi

echo "ğŸ§¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì‚­ì œ ì¤‘..."
kubectl delete namespace {tenant_specs.tenant_id}-ecp-ai --ignore-not-found=true

echo ""
echo "âœ… í…Œë„Œì‹œ '{tenant_specs.tenant_id}' ì‚­ì œ ì™„ë£Œ!"
echo ""
echo "ğŸ“Š í™•ì¸:"
echo "  kubectl get namespaces | grep {tenant_specs.tenant_id}"
"""

    def _generate_readme(self, tenant_specs: TenantSpecs) -> str:
        """README íŒŒì¼ ìƒì„±"""
        # ê¸°ë³¸ ì„œë¹„ìŠ¤ ëª©ë¡
        basic_services = ["callbot", "chatbot", "advisor", "stt", "tts", "ta", "qa"]
        services_list = "\n".join([
            f"- **{name}**: 1ê°œ ì¸ìŠ¤í„´ìŠ¤"
            for name in basic_services
        ])
        
        return f"""# ECP-AI í…Œë„Œì‹œ: {tenant_specs.tenant_id}

## ğŸ“‹ í…Œë„Œì‹œ ì •ë³´

- **í…Œë„Œì‹œ ID**: {tenant_specs.tenant_id}
- **í”„ë¦¬ì…‹**: {tenant_specs.preset}
- **GPU íƒ€ì…**: {tenant_specs.gpu_type.value}
- **ì˜ˆìƒ ë¦¬ì†ŒìŠ¤**: GPU {tenant_specs.gpu_count}ê°œ, CPU {tenant_specs.cpu_cores}ì½”ì–´

## ğŸ› ï¸ ì„œë¹„ìŠ¤ êµ¬ì„±

{services_list}

## ğŸš€ ë°°í¬ ë°©ë²•

### 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­
- Kubernetes í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ê¶Œí•œ
- kubectl ëª…ë ¹ì–´ ì„¤ì¹˜
- ì¶©ë¶„í•œ í´ëŸ¬ìŠ¤í„° ë¦¬ì†ŒìŠ¤

### 2. ë°°í¬ ì‹¤í–‰
```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x deploy.sh cleanup.sh

# ë°°í¬ ì‹¤í–‰
./deploy.sh
```

### 3. ìƒíƒœ í™•ì¸
```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -n {tenant_specs.tenant_id}-ecp-ai

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
kubectl get services -n {tenant_specs.tenant_id}-ecp-ai

# HPA ìƒíƒœ í™•ì¸
kubectl get hpa -n {tenant_specs.tenant_id}-ecp-ai
```

### 4. ë¡œê·¸ í™•ì¸
```bash
# ì „ì²´ Pod ë¡œê·¸
kubectl logs -f -l tenant={tenant_specs.tenant_id} -n {tenant_specs.tenant_id}-ecp-ai

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
kubectl logs -f deployment/<service-name> -n {tenant_specs.tenant_id}-ecp-ai
```

## ğŸ—‘ï¸ ì‚­ì œ ë°©ë²•

```bash
# ì „ì²´ í…Œë„Œì‹œ ì‚­ì œ
./cleanup.sh

# ë˜ëŠ” ìˆ˜ë™ ì‚­ì œ
kubectl delete namespace {tenant_specs.tenant_id}-ecp-ai
```

## ğŸ“Š ì˜ˆìƒ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

### GPU ìš”êµ¬ì‚¬í•­
- **GPU íƒ€ì…**: {tenant_specs.gpu_type.value}
- **GPU ê°œìˆ˜**: {tenant_specs.gpu_count}ê°œ
- **GPU ë©”ëª¨ë¦¬**: {tenant_specs.memory_gb}GB

### CPU ìš”êµ¬ì‚¬í•­  
- **CPU ì½”ì–´**: {tenant_specs.cpu_cores}ê°œ
- **ë©”ëª¨ë¦¬**: {tenant_specs.memory_gb}GB
- **ìŠ¤í† ë¦¬ì§€**: {tenant_specs.storage_gb}GB

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë¦¬ì†ŒìŠ¤ í™•ì¸**: í´ëŸ¬ìŠ¤í„°ì— ì¶©ë¶„í•œ GPU/CPU ë¦¬ì†ŒìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
2. **ë„¤íŠ¸ì›Œí¬ ì •ì±…**: ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ ì •ì±…ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
3. **ëª¨ë‹ˆí„°ë§**: Prometheus Operatorê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ ëª¨ë‹ˆí„°ë§ì´ ì‘ë™í•©ë‹ˆë‹¤
4. **ìŠ¤í† ë¦¬ì§€**: PersistentVolumeì´ í•„ìš”í•œ ì„œë¹„ìŠ¤ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ECP-AI ì§€ì›íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”.
- ì´ë©”ì¼: support@ecp-ai.com
- ë¬¸ì„œ: https://docs.ecp-ai.com
"""

    # í…œí”Œë¦¿ ì •ì˜ë“¤
    def _get_namespace_template(self) -> str:
        return """---
apiVersion: v1
kind: Namespace
metadata:
  name: {{ tenant_id }}-ecp-ai
  labels:
    tenant: {{ tenant_id }}
    app.kubernetes.io/name: ecp-ai
    app.kubernetes.io/managed-by: ecp-orchestrator
    tier: {{ tenant_preset }}
    ecp.ai/tenant-id: {{ tenant_id }}
    ecp.ai/preset: {{ tenant_preset }}
  annotations:
    ecp.ai/created-by: ecp-orchestrator
    ecp.ai/description: "ECP-AI tenant namespace for {{ tenant_id }}"
"""

    def _get_deployment_template(self) -> str:
        return """---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ service_name }}
  namespace: {{ namespace }}
  labels:
    app: {{ service_name }}
    tenant: {{ tenant_id }}
    ecp.ai/tenant-id: {{ tenant_id }}
    ecp.ai/service: {{ service_name }}
spec:
  replicas: {{ replicas }}
  selector:
    matchLabels:
      app: {{ service_name }}
      tenant: {{ tenant_id }}
  template:
    metadata:
      labels:
        app: {{ service_name }}
        tenant: {{ tenant_id }}
        ecp.ai/tenant-id: {{ tenant_id }}
        ecp.ai/service: {{ service_name }}
        monitoring: enabled
    spec:
      {% if has_gpu %}
      nodeSelector:
        accelerator: nvidia-{{ gpu_type }}
      tolerations:
      - key: nvidia.com/gpu
        operator: Equal
        value: present
        effect: NoSchedule
      {% endif %}
      containers:
      - name: {{ service_name }}
        image: {{ container_specs.image }}
        ports:
        {% for port in container_specs.ports %}
        - containerPort: {{ port.containerPort }}
          protocol: {{ port.get('protocol', 'TCP') }}
        {% endfor %}
        env:
        - name: TENANT_ID
          value: {{ tenant_id }}
        - name: SERVICE_NAME
          value: {{ service_name }}
        {% if has_gpu %}
        - name: GPU_TYPE
          value: {{ gpu_type }}
        {% endif %}
        {% for env_var in container_specs.get('env', []) %}
        - name: {{ env_var.name }}
          value: {{ env_var.value }}
        {% endfor %}
        resources:
          requests:
            {% if has_gpu %}
            nvidia.com/gpu: {{ gpu_count }}
            {% endif %}
            cpu: {{ container_specs.get('resources', {}).get('requests', {}).get('cpu', '100m') }}
            memory: {{ container_specs.get('resources', {}).get('requests', {}).get('memory', '256Mi') }}
          limits:
            {% if has_gpu %}
            nvidia.com/gpu: {{ gpu_count }}
            {% endif %}
            cpu: {{ container_specs.get('resources', {}).get('limits', {}).get('cpu', '1000m') }}
            memory: {{ container_specs.get('resources', {}).get('limits', {}).get('memory', '1Gi') }}
        livenessProbe:
          httpGet:
            path: /health
            port: {{ container_specs.ports[0].containerPort }}
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: {{ container_specs.ports[0].containerPort }}
          initialDelaySeconds: 5
          periodSeconds: 5
"""

    def _get_service_template(self) -> str:
        return """---
apiVersion: v1
kind: Service
metadata:
  name: {{ service_name }}-service
  namespace: {{ namespace }}
  labels:
    app: {{ service_name }}
    tenant: {{ tenant_id }}
    ecp.ai/tenant-id: {{ tenant_id }}
    ecp.ai/service: {{ service_name }}
    monitoring: enabled
spec:
  selector:
    app: {{ service_name }}
    tenant: {{ tenant_id }}
  ports:
  {% for port in ports %}
  - name: port-{{ port.containerPort }}
    port: {{ port.containerPort }}
    targetPort: {{ port.containerPort }}
    protocol: {{ port.get('protocol', 'TCP') }}
  {% endfor %}
  type: ClusterIP
"""

    def _get_hpa_template(self) -> str:
        return """---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ service_name }}-hpa
  namespace: {{ namespace }}
  labels:
    app: {{ service_name }}
    tenant: {{ tenant_id }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ service_name }}
  minReplicas: {{ min_replicas }}
  maxReplicas: {{ max_replicas }}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: {{ target_cpu }}
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
"""

    def _get_configmap_template(self) -> str:
        return """---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ecp-config
  namespace: {{ namespace }}
  labels:
    tenant: {{ tenant_id }}
    ecp.ai/tenant-id: {{ tenant_id }}
data:
  tenant-config.yaml: |
    tenantId: {{ tenant_id }}
    preset: {{ tenant_specs.preset }}
    services:
      callbot:
        enabled: true
        count: 1
      chatbot:
        enabled: true
        count: 1
      advisor:
        enabled: true
        count: 1
      stt:
        enabled: true
        count: 1
      tts:
        enabled: true
        count: 1
      ta:
        enabled: true
        count: 1
      qa:
        enabled: true
        count: 1
    resources:
      gpu_type: {{ tenant_specs.gpu_type.value }}
      gpu_count: {{ tenant_specs.gpu_count }}
      cpu_cores: {{ tenant_specs.cpu_cores }}
    sla:
      availability: 99.9
      response_time: 300
"""

    def _get_networkpolicy_template(self) -> str:
        return """---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ecp-ai-network-policy
  namespace: {{ namespace }}
  labels:
    tenant: {{ tenant_id }}
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          ecp.ai/tenant-id: {{ tenant_id }}
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          ecp.ai/tenant-id: {{ tenant_id }}
  - to: []
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
"""
