# [advice from AI] í•˜ë“œì›¨ì–´ ë°°ì¹˜ ìœ„ì¹˜ ì œì•ˆ ì‹œìŠ¤í…œ
"""
ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± í›„ í•˜ë“œì›¨ì–´ ë°°ì¹˜ ìœ„ì¹˜ë¥¼ ì œì•ˆí•˜ëŠ” ì‹œìŠ¤í…œ
- ë…¸ë“œ ê·¸ë£¹ë³„ ìµœì  ë°°ì¹˜ ì¶”ì²œ
- ë¦¬ì†ŒìŠ¤ ë°¸ëŸ°ì‹± ë° ë„¤íŠ¸ì›Œí¬ ìµœì í™”
- ê°€ìš©ì„± í–¥ìƒì„ ìœ„í•œ ë°°ì¹˜ ì „ëµ
"""

import math
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
import structlog

from app.models.tenant_specs import (
    HardwareNode, ServicePlacementRecommendation, ClusterTopology, 
    HardwarePlacementPlan, TenantSpecs
)

logger = structlog.get_logger(__name__)


class HardwarePlacementAdvisor:
    """í•˜ë“œì›¨ì–´ ë°°ì¹˜ ìœ„ì¹˜ ì œì•ˆ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.node_types = {
            "gpu": ["gpu-node-1", "gpu-node-2", "gpu-node-3"],
            "cpu": ["cpu-node-1", "cpu-node-2", "cpu-node-3", "cpu-node-4"],
            "storage": ["storage-node-1", "storage-node-2"],
            "infrastructure": ["infra-node-1", "infra-node-2"]
        }
        
        self.zones = ["us-west-1a", "us-west-1b", "us-west-1c"]
        
        # ë…¸ë“œë³„ ê¸°ë³¸ ìš©ëŸ‰ ì„¤ì •
        self.node_capacities = {
            "gpu": {
                "cpu": "32",  # 32 cores
                "memory": "128Gi",
                "gpu": "4",   # 4 GPUs
                "storage": "2Ti"
            },
            "cpu": {
                "cpu": "64",  # 64 cores
                "memory": "256Gi",
                "gpu": "0",   # No GPU
                "storage": "1Ti"
            },
            "storage": {
                "cpu": "16",  # 16 cores
                "memory": "64Gi",
                "gpu": "0",   # No GPU
                "storage": "10Ti"
            },
            "infrastructure": {
                "cpu": "8",   # 8 cores
                "memory": "32Gi",
                "gpu": "0",   # No GPU
                "storage": "500Gi"
            }
        }
    
    def generate_placement_plan(self, 
                               tenant_specs: TenantSpecs,
                               manifest_data: Dict[str, Any]) -> HardwarePlacementPlan:
        """
        í…Œë„Œì‹œë³„ í•˜ë“œì›¨ì–´ ë°°ì¹˜ ê³„íš ìƒì„±
        """
        try:
            logger.info("í•˜ë“œì›¨ì–´ ë°°ì¹˜ ê³„íš ìƒì„± ì‹œì‘", tenant_id=tenant_specs.tenant_id)
            
            # 1. í´ëŸ¬ìŠ¤í„° í† í´ë¡œì§€ ë¶„ì„
            cluster_topology = self._analyze_cluster_topology()
            
            # 2. ì„œë¹„ìŠ¤ë³„ ë°°ì¹˜ ì¶”ì²œ ìƒì„±
            service_placements = self._generate_service_placements(tenant_specs, manifest_data)
            
            # 3. ë¦¬ì†ŒìŠ¤ ìµœì í™” ë¶„ì„
            resource_optimization = self._analyze_resource_optimization(service_placements, cluster_topology)
            
            # 4. ë„¤íŠ¸ì›Œí¬ ìµœì í™” ë¶„ì„
            network_optimization = self._analyze_network_optimization(service_placements, cluster_topology)
            
            # 5. ê°€ìš©ì„± ì ìˆ˜ ê³„ì‚°
            availability_score = self._calculate_availability_score(service_placements, cluster_topology)
            
            # 6. ë¹„ìš© ìµœì í™” ë¶„ì„
            cost_optimization = self._analyze_cost_optimization(service_placements, cluster_topology)
            
            # 7. ì¶”ê°€ ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self._generate_recommendations(service_placements, resource_optimization, network_optimization)
            
            placement_plan = HardwarePlacementPlan(
                tenant_id=tenant_specs.tenant_id,
                cluster_topology=cluster_topology,
                service_placements=service_placements,
                resource_optimization=resource_optimization,
                network_optimization=network_optimization,
                availability_score=availability_score,
                cost_optimization=cost_optimization,
                recommendations=recommendations
            )
            
            logger.info("í•˜ë“œì›¨ì–´ ë°°ì¹˜ ê³„íš ìƒì„± ì™„ë£Œ", 
                       tenant_id=tenant_specs.tenant_id,
                       availability_score=availability_score)
            
            return placement_plan
            
        except Exception as e:
            logger.error("í•˜ë“œì›¨ì–´ ë°°ì¹˜ ê³„íš ìƒì„± ì‹¤íŒ¨", error=str(e))
            return self._generate_fallback_plan(tenant_specs)
    
    def _analyze_cluster_topology(self) -> ClusterTopology:
        """í´ëŸ¬ìŠ¤í„° í† í´ë¡œì§€ ë¶„ì„"""
        nodes = []
        
        # ê° ë…¸ë“œ íƒ€ì…ë³„ë¡œ ë…¸ë“œ ìƒì„±
        for node_type, node_names in self.node_types.items():
            for i, node_name in enumerate(node_names):
                zone = self.zones[i % len(self.zones)]
                
                node = HardwareNode(
                    node_name=node_name,
                    node_type=node_type,
                    zone=zone,
                    capacity=self.node_capacities[node_type],
                    current_usage={
                        "cpu": "0",
                        "memory": "0Gi",
                        "gpu": "0",
                        "storage": "0Gi"
                    },
                    available_resources=self.node_capacities[node_type].copy(),
                    labels={
                        "node-type": node_type,
                        "zone": zone,
                        "availability": "available"
                    },
                    taints=[]
                )
                nodes.append(node)
        
        # ë…¸ë“œ ê·¸ë£¹ë³„ ë¶„ë¥˜
        node_groups = {}
        for node_type in self.node_types.keys():
            node_groups[node_type] = [n for n in nodes if n.node_type == node_type]
        
        # ë¦¬ì†ŒìŠ¤ ë¶„í¬ í˜„í™©
        resource_distribution = {
            "total_cpu": sum(int(n.capacity["cpu"]) for n in nodes),
            "total_memory": sum(int(n.capacity["memory"].replace("Gi", "")) for n in nodes),
            "total_gpu": sum(int(n.capacity["gpu"]) for n in nodes),
            "total_storage": sum(int(n.capacity["storage"].replace("Ti", "000").replace("Gi", "")) for n in nodes)
        }
        
        return ClusterTopology(
            cluster_name="ecp-ai-cluster",
            total_nodes=len(nodes),
            node_groups=node_groups,
            zones=self.zones,
            resource_distribution=resource_distribution
        )
    
    def _generate_service_placements(self, 
                                   tenant_specs: TenantSpecs,
                                   manifest_data: Dict[str, Any]) -> List[ServicePlacementRecommendation]:
        """ì„œë¹„ìŠ¤ë³„ ë°°ì¹˜ ìœ„ì¹˜ ì¶”ì²œ ìƒì„±"""
        service_placements = []
        
        # ì„œë¹„ìŠ¤ë³„ ë°°ì¹˜ ì „ëµ
        service_strategies = {
            "callbot": {
                "node_type": "gpu",
                "priority": 1,
                "reason": "GPU ê¸°ë°˜ ìŒì„± ì²˜ë¦¬ ë° NLP ì—°ì‚°",
                "affinity": ["tts", "stt"],
                "anti_affinity": ["database", "redis"]
            },
            "chatbot": {
                "node_type": "gpu", 
                "priority": 2,
                "reason": "NLP ê¸°ë°˜ ëŒ€í™” ì²˜ë¦¬",
                "affinity": ["callbot"],
                "anti_affinity": ["database"]
            },
            "advisor": {
                "node_type": "gpu",
                "priority": 1,
                "reason": "AI ì§€ì‹ ê´€ë¦¬ ë° ë²¡í„° ê²€ìƒ‰",
                "affinity": ["callbot", "chatbot"],
                "anti_affinity": ["database"]
            },
            "stt": {
                "node_type": "cpu",
                "priority": 3,
                "reason": "CPU ê¸°ë°˜ ìŒì„± ì¸ì‹ ì²˜ë¦¬",
                "affinity": ["callbot"],
                "anti_affinity": ["tts"]
            },
            "tts": {
                "node_type": "gpu",
                "priority": 2,
                "reason": "GPU ê¸°ë°˜ ìŒì„± í•©ì„±",
                "affinity": ["callbot"],
                "anti_affinity": ["stt"]
            },
            "ta": {
                "node_type": "cpu",
                "priority": 4,
                "reason": "CPU ê¸°ë°˜ í†µê³„ ë¶„ì„",
                "affinity": [],
                "anti_affinity": ["qa"]
            },
            "qa": {
                "node_type": "cpu",
                "priority": 4,
                "reason": "CPU ê¸°ë°˜ í’ˆì§ˆ í‰ê°€",
                "affinity": [],
                "anti_affinity": ["ta"]
            }
        }
        
        # ê° ì„œë¹„ìŠ¤ì— ëŒ€í•´ ë°°ì¹˜ ì¶”ì²œ ìƒì„±
        for service_name, strategy in service_strategies.items():
            # ì„œë¹„ìŠ¤ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(tenant_specs, 'services') and tenant_specs.services:
                if service_name not in tenant_specs.services or tenant_specs.services[service_name] == 0:
                    continue
            
            # ì¶”ì²œ ë…¸ë“œ ì„ íƒ
            recommended_nodes = self._select_recommended_nodes(
                service_name, strategy["node_type"], strategy["priority"]
            )
            
            # ì–´í”¼ë‹ˆí‹° ê·œì¹™ ìƒì„±
            affinity_rules = self._generate_affinity_rules(strategy["affinity"])
            anti_affinity_rules = self._generate_anti_affinity_rules(strategy["anti_affinity"])
            
            # ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ì¶”ì •
            resource_requirements = self._estimate_resource_requirements(service_name, tenant_specs)
            
            placement = ServicePlacementRecommendation(
                service_name=service_name,
                recommended_nodes=recommended_nodes,
                placement_reason=strategy["reason"],
                resource_requirements=resource_requirements,
                affinity_rules=affinity_rules,
                anti_affinity_rules=anti_affinity_rules,
                priority=strategy["priority"]
            )
            
            service_placements.append(placement)
        
        return service_placements
    
    def _select_recommended_nodes(self, service_name: str, node_type: str, priority: int) -> List[str]:
        """ì„œë¹„ìŠ¤ë³„ ì¶”ì²œ ë…¸ë“œ ì„ íƒ"""
        available_nodes = self.node_types.get(node_type, [])
        
        if not available_nodes:
            return []
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ë…¸ë“œ ì„ íƒ
        if priority <= 2:  # ë†’ì€ ìš°ì„ ìˆœìœ„
            return available_nodes[:2]  # ìƒìœ„ 2ê°œ ë…¸ë“œ
        elif priority <= 3:  # ì¤‘ê°„ ìš°ì„ ìˆœìœ„
            return available_nodes[1:3]  # ì¤‘ê°„ 2ê°œ ë…¸ë“œ
        else:  # ë‚®ì€ ìš°ì„ ìˆœìœ„
            return available_nodes[2:]  # í•˜ìœ„ ë…¸ë“œë“¤
    
    def _generate_affinity_rules(self, affinity_services: List[str]) -> Dict[str, Any]:
        """ì–´í”¼ë‹ˆí‹° ê·œì¹™ ìƒì„±"""
        if not affinity_services:
            return {}
        
        return {
            "podAffinity": {
                "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                        "weight": 100,
                        "podAffinityTerm": {
                            "labelSelector": {
                                "matchExpressions": [
                                    {
                                        "key": "app",
                                        "operator": "In",
                                        "values": affinity_services
                                    }
                                ]
                            },
                            "topologyKey": "kubernetes.io/hostname"
                        }
                    }
                ]
            }
        }
    
    def _generate_anti_affinity_rules(self, anti_affinity_services: List[str]) -> Dict[str, Any]:
        """ì•ˆí‹°ì–´í”¼ë‹ˆí‹° ê·œì¹™ ìƒì„±"""
        if not anti_affinity_services:
            return {}
        
        return {
            "podAntiAffinity": {
                "preferredDuringSchedulingIgnoredDuringExecution": [
                    {
                        "weight": 100,
                        "podAffinityTerm": {
                            "labelSelector": {
                                "matchExpressions": [
                                    {
                                        "key": "app",
                                        "operator": "In",
                                        "values": anti_affinity_services
                                    }
                                ]
                            },
                            "topologyKey": "kubernetes.io/hostname"
                        }
                    }
                ]
            }
        }
    
    def _estimate_resource_requirements(self, service_name: str, tenant_specs: TenantSpecs) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ì¶”ì •"""
        # ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­
        base_requirements = {
            "callbot": {"cpu": "4000m", "memory": "8Gi", "gpu": "1"},
            "chatbot": {"cpu": "2000m", "memory": "4Gi", "gpu": "1"},
            "advisor": {"cpu": "3000m", "memory": "6Gi", "gpu": "1"},
            "stt": {"cpu": "4000m", "memory": "8Gi", "gpu": "0"},
            "tts": {"cpu": "2000m", "memory": "4Gi", "gpu": "1"},
            "ta": {"cpu": "2000m", "memory": "4Gi", "gpu": "0"},
            "qa": {"cpu": "1000m", "memory": "2Gi", "gpu": "0"}
        }
        
        base_req = base_requirements.get(service_name, {"cpu": "1000m", "memory": "2Gi", "gpu": "0"})
        
        # ì±„ë„ ìˆ˜ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ë§
        if hasattr(tenant_specs, 'services') and tenant_specs.services:
            channel_count = tenant_specs.services.get(service_name, 0)
            if channel_count > 0:
                scaling_factor = min(3.0, 1.0 + (channel_count / 100.0))
                
                # CPUì™€ ë©”ëª¨ë¦¬ ìŠ¤ì¼€ì¼ë§
                cpu_m = int(float(base_req["cpu"].replace("m", "")) * scaling_factor)
                memory_gi = int(float(base_req["memory"].replace("Gi", "")) * scaling_factor)
                
                base_req["cpu"] = f"{cpu_m}m"
                base_req["memory"] = f"{memory_gi}Gi"
        
        return base_req
    
    def _analyze_resource_optimization(self, 
                                     service_placements: List[ServicePlacementRecommendation],
                                     cluster_topology: ClusterTopology) -> Dict[str, Any]:
        """ë¦¬ì†ŒìŠ¤ ìµœì í™” ë¶„ì„"""
        total_cpu_requested = 0
        total_memory_requested = 0
        total_gpu_requested = 0
        
        for placement in service_placements:
            req = placement.resource_requirements
            total_cpu_requested += int(req["cpu"].replace("m", "")) / 1000  # m to cores
            total_memory_requested += int(req["memory"].replace("Gi", ""))  # Gi
            total_gpu_requested += int(req["gpu"])
        
        cluster_capacity = cluster_topology.resource_distribution
        
        optimization_score = 0
        recommendations = []
        
        # CPU ìµœì í™”
        cpu_utilization = (total_cpu_requested / cluster_capacity["total_cpu"]) * 100
        if cpu_utilization > 80:
            recommendations.append("âš ï¸ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë…¸ë“œ ì¶”ê°€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            optimization_score -= 20
        elif cpu_utilization < 30:
            recommendations.append("ğŸ’¡ CPU ì‚¬ìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ í†µí•©ì„ ê³ ë ¤í•˜ì„¸ìš”.")
            optimization_score += 10
        
        # GPU ìµœì í™”
        gpu_utilization = (total_gpu_requested / cluster_capacity["total_gpu"]) * 100
        if gpu_utilization > 90:
            recommendations.append("ğŸš¨ GPU ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì¦‰ì‹œ GPU ë…¸ë“œ ì¶”ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            optimization_score -= 30
        elif gpu_utilization < 50:
            recommendations.append("ğŸ’¡ GPU ì‚¬ìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. GPU ì„œë¹„ìŠ¤ë¥¼ ë” ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.")
            optimization_score += 15
        
        return {
            "cpu_utilization": round(cpu_utilization, 1),
            "memory_utilization": round((total_memory_requested / cluster_capacity["total_memory"]) * 100, 1),
            "gpu_utilization": round(gpu_utilization, 1),
            "optimization_score": max(0, min(100, 50 + optimization_score)),
            "recommendations": recommendations
        }
    
    def _analyze_network_optimization(self, 
                                    service_placements: List[ServicePlacementRecommendation],
                                    cluster_topology: ClusterTopology) -> Dict[str, Any]:
        """ë„¤íŠ¸ì›Œí¬ ìµœì í™” ë¶„ì„"""
        # ì„œë¹„ìŠ¤ ê°„ í†µì‹  íŒ¨í„´ ë¶„ì„
        communication_patterns = {
            "callbot": ["tts", "stt", "advisor"],
            "chatbot": ["advisor"],
            "advisor": ["callbot", "chatbot"],
            "tts": ["callbot"],
            "stt": ["callbot"]
        }
        
        network_score = 100
        recommendations = []
        
        # ê°™ì€ ë…¸ë“œì— ë°°ì¹˜ëœ ì„œë¹„ìŠ¤ë“¤ í™•ì¸
        node_placements = {}
        for placement in service_placements:
            for node in placement.recommended_nodes:
                if node not in node_placements:
                    node_placements[node] = []
                node_placements[node].append(placement.service_name)
        
        # ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì ìˆ˜ ê³„ì‚°
        for node, services in node_placements.items():
            if len(services) > 1:
                # ê°™ì€ ë…¸ë“œì— ë°°ì¹˜ëœ ì„œë¹„ìŠ¤ë“¤ ê°„ì˜ í†µì‹ ì´ ë§ì€ì§€ í™•ì¸
                for service in services:
                    if service in communication_patterns:
                        for target in communication_patterns[service]:
                            if target in services:
                                network_score += 10  # ê°™ì€ ë…¸ë“œì— ìˆìœ¼ë©´ ë„¤íŠ¸ì›Œí¬ ì§€ì—° ê°ì†Œ
                                break
        
        # ê°€ìš© ì˜ì—­ ë¶„ì‚° í™•ì¸
        zone_distribution = {}
        for placement in service_placements:
            for node in placement.recommended_nodes:
                # ë…¸ë“œì˜ ê°€ìš© ì˜ì—­ í™•ì¸
                for node_group in cluster_topology.node_groups.values():
                    for cluster_node in node_group:
                        if cluster_node.node_name == node:
                            zone = cluster_node.zone
                            zone_distribution[zone] = zone_distribution.get(zone, 0) + 1
                            break
        
        if len(zone_distribution) >= 2:
            network_score += 20  # ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì— ë¶„ì‚°ë˜ì–´ ìˆìœ¼ë©´ ê°€ìš©ì„± í–¥ìƒ
            recommendations.append("âœ… ì„œë¹„ìŠ¤ê°€ ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì— ë¶„ì‚°ë˜ì–´ ê°€ìš©ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.")
        else:
            recommendations.append("âš ï¸ ì„œë¹„ìŠ¤ê°€ ë‹¨ì¼ ê°€ìš© ì˜ì—­ì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¥ì•  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.")
            network_score -= 15
        
        return {
            "network_score": min(100, max(0, network_score)),
            "zone_distribution": zone_distribution,
            "recommendations": recommendations
        }
    
    def _calculate_availability_score(self, 
                                    service_placements: List[ServicePlacementRecommendation],
                                    cluster_topology: ClusterTopology) -> float:
        """ê°€ìš©ì„± ì ìˆ˜ ê³„ì‚°"""
        base_score = 70.0
        
        # ë…¸ë“œ ë¶„ì‚°ë„
        unique_nodes = set()
        for placement in service_placements:
            unique_nodes.update(placement.recommended_nodes)
        
        node_diversity = len(unique_nodes) / len(service_placements)
        if node_diversity > 0.8:
            base_score += 15  # ë…¸ë“œ ë¶„ì‚°ë„ê°€ ë†’ìŒ
        elif node_diversity < 0.5:
            base_score -= 10  # ë…¸ë“œ ë¶„ì‚°ë„ê°€ ë‚®ìŒ
        
        # ê°€ìš© ì˜ì—­ ë¶„ì‚°ë„
        zones_used = set()
        for node_name in unique_nodes:
            for node_group in cluster_topology.node_groups.values():
                for node in node_group:
                    if node.node_name == node_name:
                        zones_used.add(node.zone)
                        break
        
        zone_diversity = len(zones_used) / len(cluster_topology.zones)
        if zone_diversity > 0.8:
            base_score += 15  # ê°€ìš© ì˜ì—­ ë¶„ì‚°ë„ê°€ ë†’ìŒ
        elif zone_diversity < 0.5:
            base_score -= 10  # ê°€ìš© ì˜ì—­ ë¶„ì‚°ë„ê°€ ë‚®ìŒ
        
        return min(100.0, max(0.0, base_score))
    
    def _analyze_cost_optimization(self, 
                                 service_placements: List[ServicePlacementRecommendation],
                                 cluster_topology: ClusterTopology) -> Dict[str, Any]:
        """ë¹„ìš© ìµœì í™” ë¶„ì„"""
        # ë…¸ë“œ íƒ€ì…ë³„ ë¹„ìš© (ì›” ê¸°ì¤€, ì˜ˆì‹œ)
        node_costs = {
            "gpu": 500,      # GPU ë…¸ë“œ: $500/ì›”
            "cpu": 200,      # CPU ë…¸ë“œ: $200/ì›”
            "storage": 150,  # ìŠ¤í† ë¦¬ì§€ ë…¸ë“œ: $150/ì›”
            "infrastructure": 100  # ì¸í”„ë¼ ë…¸ë“œ: $100/ì›”
        }
        
        # ì‚¬ìš©ëœ ë…¸ë“œ íƒ€ì…ë³„ ë¹„ìš© ê³„ì‚°
        used_node_types = set()
        for placement in service_placements:
            for node in placement.recommended_nodes:
                for node_type, nodes in self.node_types.items():
                    if node in nodes:
                        used_node_types.add(node_type)
                        break
        
        total_monthly_cost = sum(node_costs.get(node_type, 0) for node_type in used_node_types)
        
        # ë¹„ìš© ìµœì í™” ê¶Œì¥ì‚¬í•­
        cost_recommendations = []
        if "gpu" in used_node_types and len([p for p in service_placements if "gpu" in p.recommended_nodes]) > 2:
            cost_recommendations.append("ğŸ’¡ GPU ë…¸ë“œ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. GPU ê³µìœ ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if "cpu" in used_node_types and len([p for p in service_placements if "cpu" in p.recommended_nodes]) > 3:
            cost_recommendations.append("ğŸ’¡ CPU ë…¸ë“œ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ í†µí•©ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return {
            "total_monthly_cost": total_monthly_cost,
            "used_node_types": list(used_node_types),
            "cost_per_service": round(total_monthly_cost / len(service_placements), 2),
            "recommendations": cost_recommendations
        }
    
    def _generate_recommendations(self, 
                                service_placements: List[ServicePlacementRecommendation],
                                resource_optimization: Dict[str, Any],
                                network_optimization: Dict[str, Any]) -> List[str]:
        """ì¢…í•© ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¶Œì¥ì‚¬í•­
        if resource_optimization.get("cpu_utilization", 0) > 80:
            recommendations.append("ğŸš¨ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë…¸ë“œ ì¶”ê°€ ë˜ëŠ” ì„œë¹„ìŠ¤ ë¶„ì‚°ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if resource_optimization.get("gpu_utilization", 0) > 90:
            recommendations.append("ğŸš¨ GPU ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì¦‰ì‹œ GPU ë…¸ë“œ ì¶”ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ë„¤íŠ¸ì›Œí¬ ìµœì í™” ê¶Œì¥ì‚¬í•­
        if network_optimization.get("network_score", 0) < 70:
            recommendations.append("âš ï¸ ë„¤íŠ¸ì›Œí¬ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ë°°ì¹˜ë¥¼ ì¬ê²€í† í•˜ì„¸ìš”.")
        
        # ì¼ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
        recommendations.append("âœ… ì •ê¸°ì ì¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        recommendations.append("âœ… HPA(Horizontal Pod Autoscaler) ì„¤ì •ìœ¼ë¡œ ìë™ ìŠ¤ì¼€ì¼ë§ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        recommendations.append("âœ… ë°±ì—… ë° ì¬í•´ ë³µêµ¬ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.")
        
        return recommendations
    
    def _generate_fallback_plan(self, tenant_specs: TenantSpecs) -> HardwarePlacementPlan:
        """í´ë°± ë°°ì¹˜ ê³„íš ìƒì„±"""
        logger.warning("í´ë°± ë°°ì¹˜ ê³„íš ìƒì„±", tenant_id=tenant_specs.tenant_id)
        
        return HardwarePlacementPlan(
            tenant_id=tenant_specs.tenant_id,
            cluster_topology=ClusterTopology(
                cluster_name="fallback-cluster",
                total_nodes=0,
                node_groups={},
                zones=[],
                resource_distribution={}
            ),
            service_placements=[],
            resource_optimization={},
            network_optimization={},
            availability_score=0.0,
            cost_optimization={},
            recommendations=["âš ï¸ ë°°ì¹˜ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•˜ì„¸ìš”."]
        )
